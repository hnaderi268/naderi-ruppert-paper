% !TEX root =  podc-submission.tex

\section{Analysis}
In this section, we analyze the number of steps and the number of \op{CAS} instructions performed by operations.
First, we prove some claims about the size and operations of a block. 

\begin{proposition}
Each \nf{Enqueue} or \nf{Dequeue} operation performs $O(\log p)$ \nf{CAS} instructions.
\end{proposition}
\begin{proof}
An operation invokes \nf{Refresh} at most twice at each of the $\ceil{\log_2 p}$ levels of the tree.
A \nf{Refresh} does at most 7 \nf{CAS} steps: one in line \ref{cas} and two from each \nf{Advance} in line \ref{helpAdvance} or~\ref{advance}.
\end{proof}



\begin{lemma}\label{dsearchTime}
The search that \op{FindResponse}$(b,i)$ does at line \ref{FRb} to find the index $b_e$ of the block in the root containing the $e$th enqueue takes $O(\log (\var{root}.\fld{blocks}[b_e].\size + \var{root}.\fld{blocks}[b-1].\size))$ steps.
\end{lemma}
\begin{proof}
Let the blocks in the root be $B_1, \ldots, B_\ell$.
The doubling search used to compute $b_e$ takes $O(\log (b-b_e))$ steps,
so we prove $b - b_e \leq 2 \cdot B_{b_e}.\size + B_{b-1}.\size + 1$.
If $b \leq b_e+1$, then this is trivial, so assume for the rest of the proof that $b>b_e+1$.

As shown in \Cref{linearCorrect}, the dequeue that calls \op{FindResponse} is in $B_b$ and is supposed to return an enqueue in $B_{b_e}$.
Thus, there can be at most $B_{b_e}.\size$ dequeues in 
$D(B_{b_e+1}) \cdots D(B_{b-1})$; otherwise in the sequential execution $L$,
all elements enqueued before the end of
$E(B_{b_e})$ would be dequeued before $D(B_b)$. 
Furthermore, by \Cref{sizeCorrectness}, the size of the queue  after the prefix of $L$ corresponding to 
$B_1,\ldots,B_{b-1}$  is 
$B_{b-1}.\size \geq B_{b_e}.size + |E(B_{b_e+1})\cdots E(B_{b-1})| - |D(B_{b_e+1})\cdots D(B_{b-1})|$.
Thus, $|E(B_{b_e+1})\cdots E(B_{b-1})| \leq B_{b-1}.\size + |D(B_{b_e+1})\cdots D(B_{b-1})| \leq B_{b-1}.\size + B_{b_e}.\size$.
So, the total number of operations in $B_{b_e+1}, \ldots, B_{b-1}$ is at most
$B_{b-1}.\size + 2\cdot B_{b_e}.\size$.
Each of these $b-1-b_e$ blocks contains at least one operation, by \Cref{blockNotEmpty}.
So, $b-1-b_e \leq B_{b-1}.\size + 2\cdot B_{b_e}.\size$.
\end{proof}

The following lemma is useful in bounding the time to \op{GetEnqueue}
\begin{lemma}\label{blockSize}
Each block $B$ in each node contains at most one operation of each process.
If $c$ is the execution's maximum point contention, $B$ has at most $c$ direct~subblocks.
\end{lemma}
\begin{proof}
Suppose $B$ contains an operation of process $p$.
Let $op$ be the earliest operation by $p$ contained in $B$.
When $op$ terminates, $op$ is contained in $B$ by \Cref{lem::appendExactlyOnce}.
Thus, $B$ cannot contain any later operations by $p$, since $B$ is created before
those operations are invoked.

Let $t$ be the earliest termination of any operation contained in $B$.
By \Cref{lem::appendExactlyOnce}, $B$ is created before $t$, so all operations contained in $B$
are invoked before $t$.  Thus, all are  running concurrently at $t$, so $B$ contains at most $c$ operations.
By definition, the direct subblocks of $B$ contain these $c$ operations, and each operation is contained
in exactly one of these subblocks, by Lemma \ref{lem::subblocksDistinct}.
By \Cref{blockNotEmpty}, each direct subblock of $B$ contains at least one operation,
$B$ has at most $c$ direct subblocks.
\end{proof}

--------

\begin{lemma}[Worst Case Time Analysis] \label{enqDeqTime}
The worst case number of steps for an \nf{Enqueue} is $O(\log^2 p)$ and for a \nf{Dequeue}, is $O(\log^2 p + \log q_e+ \log q_d)$, where $q_d$ is the size of the queue when the \nf{Dequeue} is linearized and $q_e$ is the size of the queue at the time the response of the \nf{Dequeue} is linearized.
\end{lemma}
\begin{proof}
\nf{Enqueue} consists of creating a block and appending it to the tree. The first part takes constant time. To propagate the operation to the root the algorithm tries at most two \nf{Refresh}es in each node of the path from the leaf to the root (Lines \ref{firstRefresh}, \ref{secondRefresh}). We can see from the code  that each \nf{Refresh} takes a constant number of steps and does $O(1)$ \nf{CAS}es. Since the height of the tree is $\Theta(\log p)$, \nf{Enqueue} takes $O(\log p)$ steps.

A \nf{Dequeue} creates a block whose \nf{element} is \nf{null}, appends it to the tree, computes its rank among non-null dequeues, finds the corresponding enqueue and returns the response. The first two parts are similar to an \nf{Enqueue} operation and take $O(\log p)$ steps. To compute the rank of a \nf{Dequeue} in $D(n)$, the \nf{Dequeue} calls \nf{IndexDequeue()}. \nf{IndexDequeue} does $O(1)$ steps in each level which takes $O(\log p)$ steps. If the response to the \nf{Dequeue} is \nf{null}, \nf{FindResponse} returns \nf{null} in $O(1)$ steps. Otherwise, if the response to a dequeue in \nf{root.blocks[end]} is in \nf{root.blocks[b]} the \nf{DoublingSearch} takes $\Theta(\log$(\nf{root.blocks[b].size+root.blocks} \nf{[end].size}) by Lemma~\ref{dsearchTime}, which is $O(\log q_e+\log q_d)$. Each search in \nf{GetEnqueue()} takes $O(\log p)$ steps since there are at most $p$ subblocks in a block (Lemma \ref{subBlocksBound}), so \nf{GetEnqueue()} takes $O(\log^2 p)$ steps.
\end{proof}


\begin{lemma}[Amortized Worst-case Analysis]
The amortized number of steps for an \nf{Enqueue} or \nf{Dequeue} is $O(\log^2 p + \log q)$,  where $q$ is the size of the queue when the operation is linearized.
\end{lemma}
\begin{proof}
If we split the \nf{DoublingSearch} time cost between the corresponding \nf{Enqueue} and \nf{Dequeue}, each operation takes $O(\log^2 p +q)$ steps.
\end{proof}

\begin{observation}
    If the maximum number of concurrent processes at any time in an execution is $c$, then the amortized worst-case step complexity is $O(\log p\log c + \log q)$ per operations. Furthermore, in a sequential, execution where $c=1$, the step complexity of our algorithm is $\Theta(\log p + \log q)$ per operation.
\end{observation}
\begin{proof}
    The analysis is similar to the two previous Lemmas, but by Lemma \ref{subBlocksBound} each \nf{BinarySearch} in each call of \nf{GetEnqueue} takes $O(\log c)$ steps.
\end{proof}

\begin{theorem}
The queue implementation is wait-free.
\end{theorem}
\begin{proof}
To prove the claim, it is sufficient to show that every \nf{Enqueue} and \nf{Dequeue} operation terminates after a finite number of its own steps. This is directly concluded from Lemma \ref{enqDeqTime}.
\end{proof}

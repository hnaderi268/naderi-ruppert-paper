We thank the reviewers for their comments.  Below, we address them point-by-point.  Modifications to the manuscript are shown in magenta.

> Reviewer 1
> Minor corrections:
> 
> line 080, right column. Emphasize that the number of CAS operations
> (log p) is another measure of the step complexity, different from
> the amortized step complexity.

Done.

> line 465. The notion sum_enq and sum_deq is confusing. Probably use
> count_enq and count_deq instead ? Or cnt_enq and cnt_deq ?

We were concerned that count might sound like a count of the number of enqueue or dequeue operations in a single block.  We instead used sum to remind the reader that the fields of Block i store the prefix sum of the number of enqueue or dequeue operations in in Blocks 1..i (as mentioned when the fields are introduced at line 504 [check line number].

> lines 526 - 528, right column. It is not clear why the expression
> for B.size is correct if some of the dequeues are empty. Additional
> intuition here will be very helpful.

Some explanation has been added.

> line 543, right column. Is B' mentioned here is the same block
> mentioned in line 521, right column ? An additional explanation
> would be helpful.

No, this was a typo, now corrected.

> lines 552 - 567, right column, and lines 686 - 711, right column.
> Adding explicit references to the lines of the code on Fig. 5 - 7
> would help to follow the explanation.

Done.

> line 558, right column. The sentence "the block's element field is
> $e$ to indicate it represents Enqueue(e) operation..." is
> confusing. It's not immediately clear why element $e$ indicates
> that the operation is Enqueue. Probably formulate it "the block's
> element field $e\neq null$ indicates..."

This paragraph has been rewritten.

> lines 594 - 608 (lines 24 - 37 in the code). Add a more detailed
> comments that explain the Refresh operation.

Done.  Quite a few new comments have been added throughout the pseudocode.

> line 619 (line 44 in the code). It's not clear why the size of the
> queue is calculated correctly. Why if some of the dequeues that are
> counted by num_deq are empty and do not change the size of the
> queue ? Some intuition here would be helpful.

Some explanation has been added in the text (line 526) [*** check line #].

> line 620 (line 46 in the code). Suggestion: consider to put the
> check whether the new block B contains no operations
> (num_deqs+num_enqs==0) immediately after the calculation of num_enq
> and num_deqs. First, complete the calculations that depend on the
> values of num_enq and num_deq, and then advance to the check
> whether v is root. If the change will be done, change the order of
> the explanation in lines 715 - 723, right column, accordingly.

Done.

> line 634 (line 58 of the code). In the comment, probably add an
> additional remainder that D(v.blocks[b]) and D(root.blocks[b'])
> represent the sequence of the dequeues represented by the
> corresponding blocks.

Added reminder in caption of Figure.

> line 640 (line 64 of the code). Add a comment that gives some
> intuition for this line.

Done.

> lines 643 - 645 (lines 67 - 69 of the code). Add comments that help
> to understand the calculation of the dequeue's rank.

Done.

> line 658 (line 81 in the code). Add additional comment that
> doubling search is used here to find the range of the binary
> search.

Done.  Some text has been added to the text description of FindResponse to explain that the doubling search first finds the left end of the range and then performs a binary search.

> line 696, right column. "... and calls Refresh on $v$ twice in
> lines 226 and 227". The lines numbers should be 17 and 18.
>
> line 701, right column. "... prior to line 226" should be "...
> prior to line 17"

These have been fixed.

> line 706, right column. Add a description of the code in lines 26 -
> 29 of Refresh.

Done.

> lines 771 - 790, left column. Add explicit references to the lines
> of the code in the description of GetEnqueue().

This has been done, and the description has been expanded.

> line 828, right column. Probably emphasize: if B and B' are two
> *different* blocks at the same depth...

Done.

> line 870, right column, Probably should be "By the definition of
> *direct* subblocks (3.3)...".

Yes, clarified.

> lines 887, 892. left column. It look like there are two unnecessary
> empty lines.

This seems to be a strange effect of the double-spacing option for the draft.

> line 919, right column. Should it be "the value computed in line
> *42*" (instead of 41) ?

Fixed.

> line 983, right column. "... close to the time ..." is not clear in
> the context of asynchronous execution. Probably state it
> differently: "We do this by showing that B.super is written after B
> is installed, but before B_s is installed."

This has been restated.

> line 1003, right column, Probably should be "By the definition of
> *direct* subblocks (3.3)...".

Fixed.

> line 1102, right column. A more detailed explanation would be
> helpful. Particulary, if op_1 precedes op_2, in which blocks op_1
> and op_2 can appear so that by (3.2) op_1 precedes op_2 in L ?

This has been expanded.

> line 1255, left column. A short explanation why Corollary 23
> follows immediately from Theorem 22 will be helpful for easier
> reading.

We found it easier to combine Theorem 22 and Corollary 23 and their
proofs (now stated together as Theorem 22).

> line 1304, right column. "...will also keep the running time of our
> operations polylogarithmic *on $p$ and $q$*"

Done.

> Reviewer 2
>
> Then, the paper presents a modification of the first algorithm that uses bounded memory, more specifically polynomial on the number of processes and the size of the queue in the linearization, and with polylogarithmic amortized step complexity. As one would naturally expect, this version adds a sort of garbage collector mechanism that removes blocks of memory that are not needed anymore. I found this part of the paper harder to understand. I did not understand the need of using red-black trees, which I think complicates everything. I have no reason to think the implementation is wrong, all looks convincing to me, but I wonder if there is a way to simplify the presentation.

For the space-bounded version, we replace an infinite array by a red-black tree (using the array index as the key).  This allows us to append elements, access elements, and split off the obsolete elements, all in logarithmic time.  We realize that this additional data structure complicates the algorithm, but we were unfortunately unable to come up with a simpler way to do it.  We hoped that presenting the simpler, space-unbounded version first would make it easier to understand the space-bounded version.  We did our best to explain the transformation from the arrays to the RBTs in the first page of Section 6.

> Specific comments:
> 
> - ln 37, left. Missing blank space before ‘and’.

Fixed.

> - I find the related work section complete. However, I wonder if it is worth citing a few works about memory reclamation, due to your bounded memory implementation.

Although our space-bounded algorithm unlinks objects that are no longer needed from our data structure, we consider the problem of reclaiming that memory to be an orthogonal issue.  There is a rather large body of literature on memory reclamation for concurrent data structures, so we have added (at line 110 of the introduction) a reference to a very recent paper that includes a large bibliography of work in this area, to help the reader find relevant literature on it. 

> - I do not understand why you do not cite the preliminary version in podc 2023. 

This omission has been corrected.

> - ln 235, left. Repeated ‘words’.

Fixed.

> - For completeness, I suggest to add a preliminaries section, with a reminder of the main definitions such as linearizability, step complexity, and so on. 

We tried to avoid the need for too many definitions and preferred to introduce them as needed instead of in a preliminaries section, since we are using fairly standard terminology.  The terms mentioned above were explained in the first paragraph of the paper.  A more formal explanation of what must be proved to establish linearizability is given in the first paragraph of Section 4.4.  Similarly, wait-free is defined when it is first used.  For completeness, we added a definition of CAS in a footnote on page 1.

> - ln 417, right. Are these direct blocks?

These are the blocks actually stored in root.blocks.  (The adjective direct is only applied to subblocks.)

> - ln 492-498. I would recall here what q stands for. Actually, I wonder if you could you use a letter that is more descriptive. 

We added the reminder.  Since q stands for queue, we thought q would remind readers of the queue's size.

> - Sec 3.4, and later. At many places operations are written in different font styles. Please follow a uniform format. 

Done.

> - ln 845-848, right. I got confused here. Lemma 4 is only about the indexes, isn't it? 

Since expression (3.3) defines subblocks in terms of indexes, we can apply Lemma 4.  Some more explanation has been added to the proof.

> - ln 1084-1088, right. Here do you mean that L is a valid sequential execution of the queue.
> 
> - Lemma 15. After reading the proof I understood that legal linearization ordering only  means respecting real-time order. This is a concrete example why I think a preliminaries section might help.
> 
> - ln 1192-1993, right. Please formalize the notion of time in an execution,
> 
> - Theorem 22. What exactly is the size of the queue?
> 
> - Sec 6. Why do you need read-back trees? How is that they facilitate the task of keeping memory bounded? Why the first algorithm cannot be modified to remove bocks, let us say using some sort of epoch-based memory reclamation scheme?

As mentioned above, we could not figure out a simpler way to do this.  

> - ln 1279-1283, left. Why? A whole path might need to be copied, isn’t it?

Since all accesses are through the root, one cannot reach a node without traversing all nodes along the path from the root to that node.  Copying those nodes then only increases the running time by a constant factor.  (The sentence has been reworded to avoid confusion.)

> - ln 1442. Why not Help(), in accordance to Dequeue(), for example?

We removed the parentheses from Dequeue for consistency.

> - Sec 7. Your algorithms are adaptive on the size of the queue but not on the number of processes. I wonder if an interesting future direction would be to make your algorithms fully adaptive.

Yes, this was mentioned in sentence 3 of Sec 7.

% !TEX root =  podc-submission.tex

\section{Reducing Space Usage}
\label{reducing}

In our implementation, an operation remains in the \nf{blocks} arrays forever. 
Thus, the space used is proportional to the number of operations that have been invoked.
Now, we sketch a mechanism to remove blocks that are no longer needed to use space
polynomial in $p$ and $q$, while maintaining polylogarithmic (amortized) step complexity.  For lack of space, details are in Appendix~\ref{reducing-details}.

We replace the \fld{blocks} array in each node by a red-black tree (RBT)
that stores the blocks.
Each block has an additional \fld{index} field
that represents its position within the original \fld{blocks} array, and
blocks in a RBT are sorted by \fld{index}.
The attempt to append a new block in entry $i$ of the \fld{blocks} array on line \ref{cas}
is replaced by an attempt to insert a new block with index $i$ into the RBT.
Accessing the block in entry $i$ in the \fld{blocks} array can then be 
replaced by searching the RBT for the block with index $i$.
The binary searches for a block in line \ref{FRb} and \ref{getChild} can simply search the RBT
using the \fld{sum\sub{enq}} field, since the RBT is also sorted with respect to this field, by \Cref{lem::sum}.
 
Known lock-free search trees have step complexity that includes a term linear in $p$ \cite{EFHR14,Ko20}.  
However, we do not require all the standard search tree operations.
Instead of a standard insertion, we allow a \op{Refresh}'s insertion to fail if another
concurrent \op{Refresh} succeeds in inserting a node, just as the CAS on line \ref{cas}
can fail if a concurrent \op{Refresh} does a successful CAS.
Moreover, the insertion should succeed only if the newly inserted block has a larger index than any other node in the RBT.
Thus, we can use a particularly simple concurrent RBT implementation.
A sequential RBT can be made persistent using the classic node-copying technique of 
Driscoll et al.~\cite{DSST89}:  all nodes are immutable, and operations on the 
tree are performed by making a new copy of each node $v$ that must be modified, as well
as each node along the path from the root to $v$.
The tree reachable from the new copy of the root is the result of applying the tree operation.
This only adds a constant factor to the running time of any routine designed for a (sequential) RBT.
Once a process has performed an update to the RBT representing the blocks of a node 
$v$ in the \ordering\ tree, 
it uses a CAS to swing $v$'s pointer from the previous RBT root to the new RBT root.
A search in the RBT can simply read the pointer to the RBT root and perform a standard
sequential search on it.
Bashari and Woelfel ~\cite{DBLP:conf/podc/BashariW21} used persistent red-black trees in a similar way to implement a snapshot data structure.

To prevent RBTs from growing without bound, we would like to discard
blocks that are no longer needed.
Ensuring the size of the RBT is polynomial in $p$ and $q$ will 
also keep the running time of our operations polylogarithmic.
Blocks should be kept if they contain operations still in progress.
Moreover, a block containing an \op{Enqueue}($x$) must be kept until $x$ is dequeued.

To maintain good amortized time per operation, we periodically do a garbage collection (GC) phase.
If a \op{Refresh} on a node adds a block whose \var{index} is a multiple of $G=p^2\ceil{\log p}$, it does GC to remove obsolete blocks from the node's RBT.
To determine which blocks can be thrown away, the node has an array $\var{last}[1..p]$ where 
each process writes the index of the last block in
containing an enqueue whose element it dequeued.
To perform GC, a process reads $\var{last}[1..p]$ and finds the maximum entry $m$.
Then, it helps complete every other process's pending dequeue 
by computing the dequeue's response and writing it in the block in the leaf that represents the dequeue.
Once this helping is complete, it follows from the FIFO property of the queue that elements enqueued 
in $\fld{blocks}[1..m-1]$ have all been dequeued, so GC can discard all blocks in the RBT 
with indices smaller than $m-1$.
Fortunately, there is an efficient \op{Split} operation that can remove
all nodes with indices smaller than $m-1$ from a RBT in logarithmic time \cite[Sec.~4.2]{Tar83}.

An operation $op$'s search of a RBT may fail to find the required block $B$ that has been removed 
by another process's GC phase.  If $op$
is a dequeue, $op$ must have been helped before $B$ was discarded, so $op$ can simply read its response from
its own leaf.
\here{What about enqueues not finding required block?}

A GC phase on a node takes $O(p\log p \log(p+q))$ steps to help complete all pending operations.
If all processes carry out this GC phase, it takes a total of $O(p^2\log p\log(p+q))=O(G\log(p+q))$ steps.
There are at least $G$ operations between two GC phases,  so for each node,
GC  contributes only $O(\log(p+q))$ steps to each operation in an amortized sense.
Adding up over all nodes an operation visits, 
an operation takes $O(\log p\log(p+q))$ steps doing GC in an amortized sense.
%Doing GC less frequently would yield better constant factors in the amortized number of steps per operation but use more space.


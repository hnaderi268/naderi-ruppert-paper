% !TEX root =  podc-submission.tex

\section{Proof of Correctness}

Consider any finite execution.  We must show that the linearization ordering $L$ defined in Section \ref{linearization} includes all operations that terminate and that 
(1) if an operation $op_1$ terminates before another operation $op_2$ begins, then $op_2$ cannot appear
before $op_1$ in $L$, and (2) each dequeue that terminates returns the same response as it would 
in $L$.

\here{need to update this outline later}
First, we define and prove some facts about blocks and the node's \nf{head} field. Then, we introduce  the linearization ordering formally. Next, we prove double \nf{Refresh} on a node is enough to propagate its children's new operations up to the node, which is used to prove (1). After this, we prove some claims about the size and operations of each block, which we use to prove the correctness of \nf{DoublingSearch()}, \nf{GetEnqueue()} and \nf{IndexDequeue()}. Finally, we prove the correctness of the way we compute the response of a dequeue, which establishes (2).

\subsection{Basic Properties}

A \typ{Block} object's fields, except for \fld{super}, are immutable:  they are written only 
when the block is created at line \ref{enqNew} or \ref{deqNew} (for a leaf's block) or lines \ref{initNewBlock}--\ref{computeLength} (for an internal node's block).  
Moreover, only a \op{CAS} at line \ref{setSuper1} can modify the \fld{super} field 
(from \nl\ to a non-\nl\ value), so it remains fixed once a value is stored in it.
Similarly, only a \op{CAS} at line \ref{cas} can modify an element of a node's \fld{blocks} array 
(from \nl\ to a non-\nl\ value), so once a block is stored in a node, it remains there forever.
Only a \op{CAS} at line \ref{incrementHead} can update a node's \head\ field by incrementing it,
which implies the following.

\begin{observation} \label{nonDecreasingHead}
For each node \var{v},  \var{v}.\fld{head} is non-decreasing over time.
\end{observation}

\begin{lemma} \label{lem::headInc}
Let $R$ be an instance of \opa{Refresh}{v} whose call to \op{CreateBlock} returns a non-\nl\ block.  When $R$ terminates, \var{v}.\head\ is greater than the value $R$ reads from it at line \ref{readHead}.
\end{lemma}
\begin{proof}
After $R$'s \op{CAS} at line \ref{incrementHead}, \var{v}.\head\ is no longer equal to the value \var{h}
read at line \ref{readHead}.  The claim follows from \Cref{nonDecreasingHead}.
\end{proof}

Now we show $v.\fld{blocks}[v.\head]$ is either the last non-\nl\ block or the first \nl\ block in node $v$.

\begin{invariant}\label{lem::headPosition} 
For $0 \leq i < v.\head$, $v.\fld{blocks}[i]\neq\nl$.  For $i>v.\head$, $v.\fld{blocks}[i]=\nl$.
If $v\neq \var{root}$,  $v.\fld{blocks}[i].super \neq \nl$ for $0<i<v.head$.
\end{invariant}

\begin{proof}
Initially, $v.\head=1$, $v.\fld{blocks}[0]\neq\nl$  and $v.\fld{blocks}[i]=\nl$ for  $i>0$, so the claims~hold.

Assume the claim holds before a change to $v.\fld{blocks}$, which can be made only
by a successful \op{CAS} at line \ref{cas}.
The \op{CAS} changes $v.\fld{blocks}[h]$ from \nl\ to a non-\nl\ value.
Since $v.\fld{blocks}[h]$ is \nl\ before the CAS, $v.\head \leq h$ by the hypothesis.
Since $h$ was read from $v.\fld{blocks}[h]$ earlier at line \ref{readHead}, 
$v.\head \geq h$ by \Cref{lem::headPosition}.
So, $h=v.\head$ and a change to $v.\fld{blocks}[v.\head]$ preserves the invariant.

Now, assume the claim holds before a change to $v.\head$, which can only be an increment from $h$ to $h+1$
by a successful \op{CAS} at line \ref{incrementHead} of \op{Advance}.
For the first two claims, it suffices to show that $v.\fld{blocks}[head] \neq \nl$.
\nf{Advance} is called either at line \ref{helpAdvance} 
after testing that $v.\fld{blocks}[h]\neq\nl$ at line \ref{ifHeadnotNull},
or at line \ref{advance} after the \op{CAS} at line \ref{cas} ensures $v.\fld{blocks}[h]\neq\nl$.
For the third claim, observe that prior to incrementing $v.\head$ at line \ref{incrementHead},
the \op{CAS} at line \ref{setSuper1} ensures that $v.\fld{blocks}[i].super\neq \nl$.
\end{proof}

It follows that blocks accessed by the \op{Enqueue}, \op{Dequeue} and \op{CreateBlock} routines are non-\nl.

The following two lemmas show that no operation appears in more than one block of the root.
\begin{lemma} \label{lem::headProgress}
 If $b>0$ and $v.\fld{blocks}[b] \neq \nl$ then 
 $v.\fld{blocks}[b-1].\fld{end\sub{left}} \leq v.\fld{blocks}[b].\fld{end\sub{left}}$ and 
 $v.\fld{blocks}[b-1].\fld{end\sub{right}} \leq v.\fld{blocks}[b].\fld{end\sub{right}}$.
\end{lemma}
\begin{proof}
Let $B$ be the block in $v.\fld{blocks}[b]$.
Before creating $B$ at line \ref{invokeCreateBlock}, the \op{Refresh} that installed $B$
read $b$ from $v.\head$ at line \ref{readHead}.
At that time, $v.\fld{blocks}[b-1]$ contained a block $B'$, by \Cref{lem::headPosition}.
Thus, the \op{CreateBlock}($v,b-1$) that created $B'$ terminated before the \op{CreateBlock}($v,b$) that
created $B$ started.
It follows from \Cref{nonDecreasingHead} that the value that 
line \ref{createEndLeft} of \op{CreateBlock}($v,b-1$) stores in $B'.\fld{end\sub{left}}$   
is less than or equal to the value that line \ref{createEndLeft} of \op{CreateBlock}($v,b$) 
stores in $B.\fld{end\sub{left}}$.
Similarly, the values stored in $B'.\eright$ and $B.\eright$ at line \ref{createEndRight} 
%of these calls to \op{CreateBlock} 
satisfy the claim.
\end{proof}

\begin{lemma} \label{lem::subblocksDistinct}
If $B$ and $B'$ are two blocks in nodes at the same depth, their sets of subblocks are disjoint.
\end{lemma}
\begin{proof}
We prove the lemma by reverse induction.
If $B$ and $B'$ are in leaves, they have no subblocks, so the claim is true.
Assume the claim is true for nodes at depth $d+1$ and let $B$ and $B'$ be two blocks in nodes at depth $d$.
Consider the direct subblocks of $B$ and $B'$ defined by (\ref{defsubblock}).
If $B$ and $B'$ are in different nodes at depth $d$, then their direct subblocks are disjoint.
If $B$ and $B'$ are in the same node, it follows from \Cref{lem::headProgress} that their direct subblocks are disjoint.
Either way, their direct subblocks (at depth $d+1$) are disjoint, so the claim follows from the induction hypothesis.
\end{proof}

It follows that each block has at most one superblock.
Moreover, we can now prove each operation is contained in at most one block of each node,
and hence appears at most once in the linearization~$L$.

\begin{corollary}\label{lem::noDuplicates}
For  $i\neq j$, $v.\fld{blocks}[i]$ and $v.\fld{blocks}[j]$ cannot both contain the same operation.
\end{corollary}
\begin{proof}
The operations contained in a block $B$ are those that appear in subblocks of $B$ in the leaves of the tree.
Since each process puts each of its operations in only one block of its own leaf, an operation 
cannot be in two different leaf blocks. 
By \Cref{lem::subblocksDistinct}, $v.\fld{blocks}[i]$ and $v.\fld{blocks}[j]$ have no subblocks in common, so the claim follows.
\end{proof}



%\begin{definition}
%$n\nf{.blocks[}i\nf{]}$ is \emph{established} if $n\nf{.head}>i$. An operation is \it{established} in node $n$ 
%if it is in an established block of $n$. $EST^t_n$ is the set of established operations in node $n$ at time $t$.
%\end{definition}
%
%Now we want to say that blocks of a node grow over time.
%\begin{observation}\label{lem::blocksOrder}
%  If  time $t<$ time $t^\prime$ ($t$ is before $t^\prime$), then $ops(n.blocks)$ at time $t$ is a subset of 
%$ops(n.blocks)$ at time $t^\prime$.
%\end{observation}
%\begin{proof}
%Blocks are only appended (not modified) with \nf{CAS} to $n\nf{.blocks[}n\nf{.head]}$, so the set of the blocks of a node after the \nf{CAS} contains the set of the blocks before the \nf{CAS}.
%\end{proof}

% \begin{corollary}\label{lem::establishedOrder}
%   If  time $t<$ time $t^\prime$, then $EST_n^t\subseteq EST_n^{t^\prime}$.
% \end{corollary}
% \begin{proof}
% From Observations \ref{nonDecreasingHead}, \ref{lem::blocksOrder}.  
% \end{proof}

The following shows that the values stored in \fld{sum\sub{enq}} and \fld{sum\sub{deq}} fields are accurate.
\here{If space is tight, could easily move next proof to appendix and just say it follows easily from the definition of subblocks and the values stored in the fields on lines \ref{enqNew}, \ref{deqNew}, \ref{createSumEnq}, \ref{createSumDeq}.}

\begin{invariant}\label{lem::sum}
If $B$ is a block stored in $v.\fld{blocks}[i]$,
$B.\fld{sum\sub{enq}} = | E(v.\fld{blocks}[0])\cdots E(v.\fld{blocks}[i]) |$ and
$B.\fld{sum\sub{deq}} = | D(v.\fld{blocks}[0])\cdots D(v.\fld{blocks}[i]) |$.
\end{invariant}
\begin{proof}
Initially, each \fld{blocks} array only contains an empty block $B_0$ in location 0.
By definition, $E(B_0)$ and $D(B_0)$ are empty sequences.
Moreover, $B_0.\fld{sum\sub{enq}} = B_0.\fld{sum\sub{deq}} = 0$, so the claim is true.

We show that each installation of a block $B$ into some location $v.\fld{blocks}[i]$ preserves the claim,
assuming the claim holds before this installation.  We consider two cases.

If $v$ is a leaf, $B$ was created at line \ref{enqNew} or \ref{deqNew}.
For line \ref{enqNew}, $B$ represents a single enqueue operation, so $|E(B)|=1$ and $|D(B)|=0$.
Moreover, $B.\fld{sum\sub{enq}}$ is set to $v.\fld{blocks}[i-1]+1$ and
$B.\fld{sum\sub{deq}}$ is set to $v.\fld{blocks}[i-1]$, so the claim follows from the hypothesis.
The proof for line \ref{deqNew}, where $B$ represents a single dequeue operation is similar.

Now suppose $v$ is an internal node. By the definition of subblocks in (\ref{defsubblock}), the
subblocks of $v.\fld{blocks}[1..i]$ are $v.\fld{left.blocks}[1..B.\eleft]$ 
and $v.\fld{right.blocks}[1..B.\eright]$.
Thus, the enqueues in $E(v.\fld{blocks}[0])\cdots E(v.\fld{blocks}[i])$ are those in
$E(v.\fld{left.blocks}[0]) \cdots E(v.\fld{left.blocks}[B.\eleft])$ and
$E(v.\fld{left.blocks}[0]) \cdots E(v.\fld{left.blocks}[B.\eright])$.
By the hypothesis, the total number of these enqueues is $v.\fld{left.blocks}[B.\eleft].\fld{sum\sub{enq}} + v.\fld{right.blocks}[B.\eright].\fld{sum\sub{enq}}$, which is the value that line \ref{createSumEnq} stored in $B.\fld{sum\sub{enq}}$ when $B$ was created.
The proof for \fld{sum\sub{deq}} (stored on line~\ref{createSumDeq}) is similar.
\end{proof}

This allows us to prove that every block a Refresh installs contains at least one operation.

\begin{corollary}\label{blockNotEmpty}
If a block $B$ is in $v.\fld{blocks}[i]$ where $i>0$, then $E(B)$ and $D(B)$ are not both empty.
\end{corollary}
\begin{proof}
The \op{Refresh} that installed $B$ got $B$ as the response to its call to \op{CreateBlock} on line \ref{invokeCreateBlock}.
Thus, at line \ref{testEmpty} $\var{num\sub{enq}}+\var{num\sub{deq}}\neq 0$.
By \Cref{lem::sum}, $\var{num\sub{enq}} = |E(B)|$ and $\var{num\sub{deq}} = |D(B)|$,
so these sequences cannot both be empty.
\end{proof}



\subsection{Propagating Operations to the Root}
Next, we show two \op{Refresh}es suffice to propagate operations from a child to its parent.
We say that node $v$ \emph{contains} an operation if some block in $v.\fld{blocks}$ contains the operation.
\here{move this defn earlier and just recall it here?}
Once a block is added to a node, it remains there forever.  Thus, if $v$ contains an operation at some time, it contains the operation at all later times too.

\begin{lemma}\label{successfulRefresh}
Let $R$ be a call to \op{Refresh}($v$) that performs a successful \op{CAS} on line \ref{cas} (or terminates at line \ref{addOP}).
In the configuration after that CAS (or termination, respectively), $v$ contains all operations that $v$'s children contained 
when $R$ executed line~\ref{readHead}.
\end{lemma}
\begin{proof}
Suppose $v$'s child (without loss of generality, $v.\fld{left}$) contained an operation $op$ 
in the configuration $C$ immediately before $R$ executed line \ref{readHead}.
Then some block $B$ in $v.\fld{left.blocks}[i]$ contains $op$.
By \Cref{nonDecreasingHead} and \Cref{lem::headProgress}, the value of $childHead$ that $R$ reads from
$v.\fld{left.head}$ in line \ref{readChildHead} is at least $i$.
If it is equal to $i$, $R$ calls \op{Advance} at line \ref{helpAdvance}, which ensures that 
$v.\fld{left.head} > i$.
Then, $R$ calls \op{CreateBlock}($v,h$) in line \ref{invokeCreateBlock}, where $h$ is the value $R$ reads at line \ref{readHead}.
\op{CreateBlock} reads a value greater than $i$ from $v.\fld{left.head}$ at line \ref{createEndLeft}.
Thus, $new.\eleft \geq i$.  We consider two cases.

Suppose $R$'s call to \op{CreateBlock} returns the new block $B'$ and $R$'s \op{CAS} at line \ref{cas} 
installs $B'$ in $v.\fld{blocks}$.
Then, $B$ is a subblock of some block in $v$, since  $B'.\eleft$ is greater than or equal to $B$'s index
in $v.\fld{left.blocks}$.
Hence $B'$ contains $op$, as required.

\Eric{I think this case was missing from the proof in the thesis}
Now suppose $R$'s call to \op{CreateBlock} returns \nl, causing $R$ to terminate at line \ref{addOP}.
Intuitively, since there are no operations in $v$'s children to promote, $op$ is already in $v$.
We formalize this intuition.
The value computed at line \ref{createSumEnq} is
\begin{eqnarray*}
\var{num\sub{enq}} 
&=& v.\fld{left.blocks}[new.\eleft].\fld{sum\sub{enq}} + v.\fld{right.blocks}[new.\eright].\fld{sum\sub{enq}} - v.\fld{blocks}[h-1].\fld{sum\sub{enq}} \\
&=& v.\fld{left.blocks}[new.\eleft].\fld{sum\sub{enq}} + v.\fld{right.blocks}[new.\eright].\fld{sum\sub{enq}} \\
&&\mbox{ }- v.\fld{left.blocks}[v.\fld{blocks}[h-1].\eleft].\fld{sum\sub{enq}} - v.\fld{right.blocks}[v.\fld{blocks}[h-1].\eright].\fld{sum\sub{enq}}
\end{eqnarray*}
It follows from \Cref{lem::sum} that $num\sub{enq}$ is the total number of enqueues contained in the blocks
$v.\fld{left.blocks}[v.\fld{blocks}[h-1].\eleft+1..new.\eleft]$ and
$v.\fld{right.blocks}[v.\fld{blocks}[h-1].\eright+1..new.\eright]$.
Similarly, $num\sub{deq}$ is the total number of dequeues contained in these blocks.
Since $num\sub{enq}+num\sub{deq}=0$ at line \ref{testEmpty},
these blocks contain no operations.
By \Cref{blockNotEmpty}, this means the ranges of blocks are empty, so that $v.\fld{blocks}[h-1].\eleft \geq new.\eleft \geq i$.
Hence, $B$ is already a subblock of some block in $v$, so $v$ contains $op$.
\end{proof}

We now show that if a process fails its \op{Refresh}($v$) twice, some other process must have succeeded.

\begin{lemma}\label{lem::doubleRefresh}
Consider two consecutive terminating calls $R_1$, $R_2$ to \nf{Refresh}($v$) by the same process.
When $R_2$ terminates, $v$ contains all operations that $v$'s children contained when $R_1$ was invoked.
\end{lemma}
\begin{proof}
If either $R_1$ or $R_2$ performs a successful \op{CAS} at line \ref{cas} or terminates at line \ref{addOP}, the claim follows
from Lemma \ref{successfulRefresh}.
So suppose both $R_1$ and $R_2$ perform a failed \op{CAS} at line \ref{cas}.
Let $h_1$ and $h_2$ be the values $R_1$ and $R_2$ read from $v.\head$ at line \ref{readHead}.
By \Cref{lem::headInc}, $h_2>h_1$.
By \Cref{lem::headProgress}, $v.blocks[h_2]=\nl$ when $R_1$ executes line \ref{readHead}.
Since $R_2$ fails its \op{CAS} on $v.blocks[h_2]$, some other \op{Refresh} $R_3$ must have done
a successful \op{CAS} on $v.blocks[h_2]$ before $R_2$'s \op{CAS}.
$R_3$ must have executed line \ref{readHead} after $R_1$, since $R_3$ read the value $h_2$ from $v.\head$ and the value of $v.\head$ is non-decreasing, by \Cref{nonDecreasingHead}.
Thus, all operations contained in $v$'s children when $R_1$ begins
are also contained in $v$'s children when $R_3$ later executes line \ref{readHead}.
By \Cref{successfulRefresh}, these operations are contained in $v$ when $R_3$ performs its successful \op{CAS},
which is before $R_2$ terminates.
\end{proof}

\begin{lemma} \label{lem::appendExactlyOnce}
When an \op{Append}($B$) terminates, $B$'s operation is contained in exactly one block in each node along the path from the process's leaf to the root.
\end{lemma}
\begin{proof}
The \op{Append} adds $B$ to the process's leaf and calls \op{Propagate}, which
performs a double \op{Refresh} on each node along the path from the leaf's parent to the root.
By \Cref{lem::doubleRefresh}, this ensures $B$'s operation is contained in each node along this path.
By \Cref{lem::noDuplicates}, it is contained in exactly one block in each node.
\end{proof}

\subsection{Correctness of GetEnqueue}

\begin{lemma}\label{lem::get}
If $1\leq i\leq |E(v.\fld{blocks}[b])|$ then \op{getEnqueue}($v,b,i$) returns the argument of the $i$th enqueue in $E(v.\fld{blocks}[b])$.
\end{lemma}
\begin{proof}
We prove the claim by induction on the height of node $v$.
If $v$ is a leaf, the hypothesis implies that $i=1$ and the block $v.\fld{blocks}[b]$ represents 
an enqueue whose argument is stored in $v.\fld{blocks}[b].\fld{element}$.
\op{GetEnqueue} returns the argument of this enqueue at line \ref{getBaseCase}.

Assuming the claim holds for $v$'s children, we prove it for $v$.
Let $B$ be $v.\fld{blocks}[b]$.
By (\ref{defSeqs}),
$E(B)$ is obtained by concatenating the enqueue sequences of the direct subblocks
of $B$, which are listed in (\ref{defsubblock}).
By \Cref{lem::sum}, $\var{sum\sub{left}}-\var{prev\sub{left}}$ is the number
of enqueues in $E(B)$ that come from $B$'s subblocks in $v$'s left child.
Thus, $dir$ is set to the direction for the child of $v$ that contains the required enqueue.
Moreover, when line \ref{endChooseDir} is reached, $i$ is the position of the required enqueue within the portion $E'$ of $E(B)$ that comes from that child.
Thus,  line \ref{getChild} finds the index $b'$ of the subblock $B'$ containing the required enqueue.
By \Cref{lem::sum}, $v.\var{dir.blocks}[b'-1].\var{sum\sub{enq}} - \var{prev\sub{dir}}$ is the number of 
enqueues in $E'$ before the enqueues of block $B'$, so
the value $i'$ computed on line \ref{getChildIndex} is the position of the required enqueue within $E(B')$.
Thus, the recursive call on line \ref{getRecurse} satisfies its precondition, and 
returns the required result, by the induction hypothesis.
\end{proof}

\subsection{Correctness of IndexDequeue}

Next, we prove the \fld{super} field of a block is within one of the true index of the block's superblock.
\here{An alternative would be modify the code
so that the correct index of the superblock is computed before storing it in $B.super$.
In Advance, we could check if $h>v.parent.blocks[h_p].end_{left/right}$ and if so write $h_p+1$ instead of $h_p$ in $v.blocks[h].super$.  Then, in IndexDequeue there would be no need to correct the value read from the super field.  If we do this, the following lemma would be modified to prove that the value is perfectly accurate.}

\begin{lemma}\label{superRelation}
Let $B=v.\var{blocks}[b]$.
  If $v.\fld{parent.blocks}[s]$ is the superblock of $B$ then $s-1\leq B.\fld{super}\leq s$.
\end{lemma}
\begin{proof}
We first show $B.\fld{super}\leq s$.
Let $R_s$ be the instance of \op{Refresh}($v.\fld{parent}$) that installs the superblock of $B$ 
in $v.\fld{parent.blocks}[s]$.
By the definition of subblocks (\ref{defsubblock}), $R_s$'s read $r$ of $v.head$ at line \ref{createEndLeft} or \ref{createEndRight} obtains a value greater than $b$.
By \Cref{lem::headPosition}, $B.\fld{super} \neq \nl$ when $r$ occurs, which means
that $B.\fld{super}$ was set (by line~\ref{setSuper1}) to a value read from $v.\fld{parent}.\head$ before $r$.
When $r$ occurs, $v.\fld{parent.blocks}[s] = \nl$, since the later \op{CAS} by $R_s$ at line
\ref{cas} succeeds.
So, by \Cref{lem::headPosition}, $v.\fld{parent}.\head \leq s$ when $r$ occurs.
Since the value stored $B.\fld{super}$ was read from $v.\fld{parent.head}$ before $r$ and the \head\ field is non-decreasing by \Cref{nonDecreasingHead}, it follows that $B.super\leq s$.

Next, we show that $B.\fld{super}\geq s-1$.
The value stored in $B.\fld{super}$ at line \ref{setSuper1} is read from $v.\fld{parent}.\head$ at line \ref{readParentHead} and \head\ values are always at least 1, so $B.\fld{super} \geq 1$.
So, if $s\leq 2$, the claim is trivial.  Assume for the remainder that $s>2$.
By \Cref{lem::headProgress}, $v.\fld{parent.blocks}[s-1]\neq \nl$.  Let $R_{s-1}$ be the call to
$\op{Refresh}(v.\fld{parent})$ that installed the block in $v.\fld{parent.blocks}[s-1]$.
Let $r'$ be the step when $R_{s-1}$ reads $s-1$ in $v.\fld{parent}.\head$ at line \ref{readHead}.
This read $r'$ must be before $B$ is installed in $v$;
otherwise, \Cref{successfulRefresh} would imply that $B$ is a subblock of one of 
$v.\fld{parent.blocks}[1..s-1]$, contrary to the hypothesis.
Now, consider the call to \op{Advance}($v, b$) that writes $B.\fld{super}$.
It is invoked either 
at line \ref{helpAdvance} after seeing $v.\fld{blocks}[h]\neq \nl$ at line \ref{ifHeadnotNull}
or at line \ref{advance} after ensuring $v.\fld{blocks}[h]\neq \nl$ at line~\ref{cas}.
Either way, the \op{Advance} is invoked after $B$ is installed, and therefore after $r'$.
By \Cref{nonDecreasingHead}, $v.\fld{parent}.\head$ is non-decreasing, so 
the value this \op{Advance} reads in $v.\fld{parent}.\head$ and
writes in $B.\fld{super}$ is greater than or equal to the value $s-1$ that $r'$ reads in $v.\fld{parent}.\head$.
\end{proof}

%The reader may wonder when the case $b\nf{.super}=s$ happens. This can happen when $
%\nf{$n$.parent.blocks[$B$.super]}=\nf{null}$ when $B$\nf{.super} is written and $R_p$ puts its created block 
%into \nf{$n$.parent.blocks[$B$\nf{.super}]} afterwards.

We prove \op{IndexDequeue}'s correctness using \Cref{superRelation} on each step of the \op{IndexDequeue}.
\here{mention somewhere why precondition of IndexDequeue is true; also check that block of parent indexed by sup in that routine is non-null}

\begin{lemma}
If $v.\fld{blocks}[b]$ has been propagated to the root and $1\leq i\leq |D(v.\fld{blocks}[b])|$, 
 then \op{IndexDequeue}($v, b, i$) returns $\langle b',i'\rangle$ such that the \var{i}th dequeue in $D(\var{v}.\fld{blocks}[\var{b}])$ is the $(i')$th dequeue of $D(\var{root}.\fld{blocks}[b'])$.
\end{lemma}
\begin{proof}
We prove the claim by induction on the depth of node $v$. The base case where $v$ is the root is trivial (see Line \ref{indexBaseCase}).
Assuming the claim holds for $v$'s parent, we prove it for $v$.
Let $B=v.\fld{blocks}[b]$ and $B'$ be the superblock of $B$.
\op{IndexDequeue}($v, b, i$) first computes the index $sup$ of $B'$ in $v.\fld{parent}$.
By \Cref{superRelation}, this index is either $B.super$ or $B.super+1$.
The correct index is determined by testing on line \ref{supertest} whether $B$ is not a subblock of $v.\fld{parent.blocks}[B.\fld{super}]$.

Next, the position of the required dequeue in $D(B')$ is computed in 
lines \ref{computeISuperStart}--\ref{computeISuperEnd}. 
We first add the number of dequeues in the subblocks of $B'$ in $v$ that preced $B$ on line \ref{computeISuperStart}.
If $v$ is the right child of its parent, then all of the subblocks of $B'$ from $v$'s left sibling
also precede the required dequeue, so we add the number of dequeues in those subblocks in line \ref{considerLeftBeforeRight}.

Finally, \op{IndexDequeue} is called recursively on $v$'s parent.
Since $B$ has been propagated to the root, so has its superblock $B'$.
Thus, all preconditions of the recursive call are met.
By the induction hypothesis, the recursive call returns the location of the required dequeue in the root.\end{proof}

----------

\subsection{Linearizability}
We now prove the two properties needed for linearizability.

\begin{lemma} \label{linearSat}
$L$ is a legal linearization ordering.
\end{lemma}
\begin{proof}
We must show for any execution that every operation that terminates is in $L$ exactly once. Also, if $op_{1}$ terminates before $op_{2}$ in starts in the execution, then $op_{1}$ is before $op_{2}$ in the linearization. The first claim is directly reasoned from Corollary \ref{lem::appendExactlyOnce}. For the latter, if $op_{1}$ terminates before $op_{2}$ starts,  $op_{1}$\nf{.Append} has terminated before $op_{2}$\nf{.Append} started. From Corollary \ref{lem::append}, $op_{1}$ is in \nf{root.blocks} before $op_{2}$ starts to propagate. By definition of $L$, $op_{1}$ is linearized before $op_{2}$.
\end{proof}
Once some operations are aggregated in one block, they will get propagated up to the root together, and they can be linearized in any order among themselves. We have chosen to put \nf{Enqueue}s in a block before \nf{Dequeue}s (see Definition \ref{ordering}).

\begin{definition}\label{defNullDeq}
If a \nf{Dequeue} operation returns \nf{null} it is called a \it{null} \nf{Dequeue}, otherwise it is called \it{non-null}~\nf{Dequeue}.
\end{definition}

Next, we define the responses that \nf{Dequeue}s should return, according to the linearization.
\begin{definition}
   Assume the operations in \nf{root.blocks} are applied sequentially on an empty queue in the order of $L$.  ${Resp(d)=e}$\nf{.element} if the element of \nf{Enqueue} $e$ is the response to \nf{Dequeue} $d$. Otherwise if ${d}$ is a null \nf{Dequeue} then ${Resp(d)=\nf{null}}$. 
\end{definition}

In the next lemma, we show that the \nf{size} field in each \nf{root block} is computed correctly.
\begin{lemma}\label{sizeCorrectness}
  \nf{root.blocks[$b$].\size}is the \size of the queue after the operations in \nf{root.blocks[$0 \cdot$\\$\cdot\cdot b$]} are applied in the order of~$L$.  
\end{lemma}
\begin{proof}
We prove the claim by induction on $b$. The base case when ${b=0}$ is trivial since the queue is initially empty and $\nf{root.blocks[}0\nf{]}$ contains an empty block with \nf{size} field equal to $0$. We are going to show the correctness when $b=i$ assuming  correctness when $b=i-1$. By Definition \ref{ordering} \nf{Enqueue} operations come before \nf{Dequeue} operations in a block in $L$. By Lemma~\ref{lem::numX} \nf{num\sub{enq}} and \nf{num\sub{deq}} fields in a block show the number of \nf{Enqueue} and \nf{Dequeue} operations in it. If there are more than $\nf{root.blocks[}i-1\nf{].size}+\nf{root.blocks[}i\nf{].num\sub{enq}}$ dequeue operations in \nf{root.blocks[$i$]} then the queue would become empty after \nf{root.blocks[$i$]}. Otherwise, the size of the queue after the $b$th block in the root is $\nf{root.blocks[}b-1\nf{].size}+ \nf{root.blocks[}b\nf{].num\sub{enq}}- \nf{root.blocks[}b\nf{].num\sub{deq}}$. In both cases, this is the same as the assignment on Line \ref{computeLength}.
\end{proof}

The next lemma is useful to compute the number of non-null dequeues.
\begin{lemma} \label{numberOfNND}
If operations in the root are applied in the order of $L$, the number of non-null \nf{Dequeue}s in $\nf{root.blocks[}0\cdots b\nf{]}$ is \nf{root.blocks[$b$].sum\sub{enq} $-$ root.blocks[$b$].size}.
\end{lemma}
\begin{proof}
There are \nf{root.blocks[$b$]}\nf{.sum\sub{enq}} \nf{Enqueue} operations in $\nf{root.blocks[}0\cdots b\nf{]}$ by Corollary~\ref{lem::sumX}. The size of the queue after doing $\nf{root.blocks[}0\cdots b\nf{]}$ in the order of $L$ is 
the number of $\it{enqueues}$ in $\nf{root.blocks[}0\cdots b\nf{]}$ minus the number of $\it{non-null \nf{Dequeue}s}$ in $\nf{root.blocks[}0\cdots b\nf{]}$. By the correctness of the \nf{size} field from Lemma \ref{sizeCorrectness} and \nf{sum\sub{enq}} field from Lemma \ref{lem::numX}, the number of $\it{non-null \nf{Dequeue}s}$ is \nf{root.blocks[$b$]}\nf{.sum\sub{enq}} $-$ \nf{root.blocks[$b$]}\nf{.size}. 
\end{proof}

\begin{corollary}\label{numNullDeqBlock}
  If operations in the root are applied in the order of $L$, the number of non-null dequeues in $\nf{root.blocks[}b\nf{]}$ is \nf{root.blocks[$b$].num\sub{enq} $-$ root.blocks[$b$].\size $+$ root.blocks[$b-1$].size}.
\end{corollary}

\begin{lemma}\label{nullReturn}
$Resp(D_i(\nf{root},b))$ is \nf{null} iff \nf{root.blocks[$b-1$].\size $+$ root.blocks[$b$].num\sub{enq}$- i$ $<0$}.
\end{lemma}
\begin{proof}
The claim follows immediately from Corollary  \ref{numNullDeqBlock} and Lemma \ref{lem::numX}.
\end{proof}

\begin{lemma}\label{computeHead}
\nf{FindResponse($b$, $i$)} returns $Resp(D_i(root,b))$.
\end{lemma}
\begin{proof}
$D_i(root,b)$ is $D_{\nf{root.blocks[}b-1\nf{].sum\sub{deq}}+i}(root)$ by Definition \ref{ordering} and Lemma \ref{lem::sumX}. $D_i(root,b)$ returns \nf{null} at Line \ref{returnNull} if $\nf{root.blocks[}b-1\nf{].size}+ \nf{root.blocks[}b\nf{].num\sub{enq}}- i <0$ and $Resp(D_i(root,b))=\nf{null}$ in this case by Lemma \ref{nullReturn}. Otherwise, if $D_i(root,b)$ is the $e$th non-null \nf{Dequeue} in $L$ it should return the $e$th enqueued value. By Lemma \ref{numberOfNND} there are \nf{root.blocks[$b-1$].sum\sub{enq} $-$ root.blocks[$b-1$].\size} non-null \nf{Dequeue} operations in $\nf{root.blocks[}0\cdots b-1\nf{]}$. The \nf{Dequeue}s in \nf{root.blocks[$b$]} before $D_i(root,b)$ are non-null \nf{Dequeue}s. So $D_i(root,b)$ is the $e$th non-null \nf{Dequeue} where $e= i + \nf{root.blocks[}b-1\nf{].sum\sub{deq}} - \nf{root.blocks[}b-1\nf{].size}$ (Line \ref{computeE}). See Figure \ref{computeResponseDetail}.

After computing $e$ at Line \ref{computeE}, the code finds \nf{$b$,$i$} such that $E_i(root,b)=E_e(root)$ using \nf{DoublingSearch} and then finds its \nf{element} using \nf{GetEnqueue} (Line \ref{findAnswer}). Correctness of \nf{DoublingS-}\\\nf{earch} and \nf{GetEnqueue} routines are shown in Lemmas \ref{dsearch} and \ref{get}.
\end{proof}

\begin{figure}[hbt]  
  \center\includegraphics[width=4in, height=2.5in]{pics/computeResponseDetail.png}\caption{The position of $D_i(root,b)$.}
\label{computeResponseDetail}
\end{figure}
\vspace{-1em}

\begin{lemma}\label{linearCorrect}
The responses to operations in our algorithm are the same as in the sequential execution in the order given by $L$.
\end{lemma}
\begin{proof}
\nf{Enqueue} operations do not return any value. By Lemma \ref{computeHead}, the response of a \nf{Dequeue} in our algorithm is the same as its response in the sequential execution of $L$.  
\end{proof}

\begin{theorem}[Main]
The queue implementation is linearizable.
\end{theorem}
\begin{proof}
The theorem follows from Lemmas \ref{linearSat} and \ref{linearCorrect}.
\end{proof}


\here{following material from algorithm description in thesis might be useful in sketch of correctness proof}
\begin{figure}[hbpt]
  \center\includegraphics[width=4in]{pics/doublyrefresh-drawio.png}
  \caption[Two consecutive failed \nf{Refresh}es by a
    process.]{\label{fig::simpleDoubleRefresh}Time relations between
    the concurrent successful \nf{Refresh}es and the two consecutive
    failed \nf{Refresh}es.} 
\end{figure}
We use \nf{CAS} (Compare\&Swap) instructions to implement the
\nf{Refresh}'s attempt to append  described in the previous
paragraph. 
The second failed \nf{Refresh} of $P$ is assuredly concurrent with a
successful \texttt{Refresh} that has read its information after the
invocation of the first failed \nf{Refresh} (see Figure
\ref{fig::simpleDoubleRefresh}). This is because some process $L$ does
a successful append during $P$'s first failed attempt, and some
process $K$ performs a \nf{Refresh} that reads its information after
$L$'s append and then performs a successful append during $P$'s second
failed \nf{Refresh}. Process $K$'s \nf{Refresh} helps to append the
new operations that were in $n$'s children before $P$'s first failed
\nf{Refresh}, in case they were not already appended. After a process
appends its operation into its leaf it can call \nf{Refresh} on the
path up to the root at most two times on each node. So, with $O(\log
p)$ \nf{CAS}es an operation can ensure it appears in the
linearization. This cooperative solution allows us to overcome the CAS
Retry Problem. 


